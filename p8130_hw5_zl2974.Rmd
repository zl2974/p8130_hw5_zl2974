---
title: "p8130 homework 5"
author: "Jeffrey Liang"
date: "11/15/2020"
output: 
  pdf_document:
    latex_engine : "xelatex"
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(patchwork)
knitr::opts_chunk$set(
  fig.height = 6,
  fig.width = 8,
  message = F,
  echo = F,
  warning = F
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis",
  digits = 3
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```


# Problem 1

For this problem youwill use dataset ‘Antibodies.csv’from homework 1. In the first assignmentyou generated descriptive statisticsand exploratory plotsfor the Ig-M levels by Normal vs Altered groups. The conclusion was that Ig-M distributions were both right skewedwithhigher levels for the Altered group. Given the non-normal distributions, now you are asked touse an alternative, non-parametrictest to assess and comment on the differencein Ig-M levelsbetween the two groups (please ignore unanswered andmissing values).You can use R to perform the calculations, but make sure you statetest that you used,the hypotheses, test statistic, p-value and provide interpretation in the context of the problem.

```{r p1}
antibody =
  read_csv(here::here("data/Antibodies.csv")) %>%
  janitor::clean_names() %>%
  filter(smell != "Unanswered/Others")%>%
  drop_na(smell, antibody_ig_m) 

antibody =
  antibody %>%
  mutate(rank = rank(antibody_ig_m)) %>%
  pivot_wider(names_from = smell,
              values_from = antibody_ig_m) %>%
  arrange(rank) %>% 
  select(rank,Normal,Altered)

test_antibody =
  wilcox.test(antibody %>% pull(Normal),antibody %>% pull(Altered), mu = 0)

t1 = antibody %>% drop_na(Normal) %>% summarise(t1 = sum(rank)) %>% pull(t1)

tied = antibody %>% count(rank) %>% filter(n>1) %>% pull(n)

n1 = nrow(drop_na(antibody, Normal))

n2 = nrow(drop_na(antibody, Altered))

test_antibody$statistic =
  test_antibody$statistic +
  n1*(n1 + 1)/2

T = (abs(t1 - n1 * (n1+n2 + 1) / 2) - 0.5)
T = T/sqrt(n1*n2/12 * (n1 +n2 + 1 - sum(tied*(tied^2-1))/((n1+n2)*(n1+n2-1))))
```

a. 

The data do not fit the normality assumption, given two groups are give, we choose Wilcoxson Rank 
Sum test for this question.

H0 : The median of IgM level in Normal smell group is the same as Altered smell groups.

H1 : The median of ImG level is different between groups.

if no tied ranks:
$$T = \frac{|T_1 - n_1(n_1+n_2+1)/2|-\frac{1}{2}}{\sqrt{(n_1n_2/12)(n_1+n_2+1)}}$$
if there's tied ranks:
$$T = \frac{|T_1 - n_1(n_1+n_2+1)/2|-\frac{1}{2}}{\sqrt{(n_1n_2/12)[(n_1+n_2+1) - \sum^{tied~group}t_i(t_i^2-1)/(n_1+n_2)(n_1+n_2-1)]}}$$

Under the normal-approximation, we reject H0 if $T > Z_{1−α/2}$, with p−value = $2 ×[1- \Phi(T)]$.

```{r}
antibody %>% head() %>% knitr::kable()
```

A peek at the rank's table, we know that there's tied rank, so we used the adjusted method.

$$t1 =`r t1`$$

$$Ties = `r tied %>% sum()`$$

$$T = `r T` > Z_{1-0.975} = `r qnorm(0.975)`$$

```{r}
test_antibody %>% knitr::knit_print()

test_antibody =
  test_antibody %>%
  broom::tidy()
```

 So at 95% level, we reject the Null and conclude that the median of IgM level in Normal group differs from the
 Altered group.$\blacksquare$

# Problem 2

```{r p2, echo=FALSE, out.width = '100%'}
knitr::include_graphics(here::here("file/proof_p2.jpg"))
```
\newpage

# Problem 3

The director of admissions of a small college selected 120 students at random from the new
freshman class in a study to determine whether a student’s GPA at the end of the freshman year
(Y) can be predicted from the ACT test score (X). Use data ‘GPA.csv’ to answer the following
questions:
You can use R to perform/check the calculations, but you need to show the formulae where
asked to do so.

1. Generate a scatter plot and test whether a linear association exists between student’s ACT
score (X) and GPA at the end of the freshman year (Y). Use a level of significance of 0.05.
Write the hypotheses, test statistics, critical value and decision rule with interpretation in the
context of the problem. (7.5p)

2. Write the estimated regression line equation in the context of this problem. (2.5p)

3. Obtain a 95% confidence interval for β1. Interpret your confidence interval. Does it include
zero? Why might the director of admissions be interested in whether the confidence interval
includes zero? (2.5p)

4. Obtain a 95% interval estimate of the mean freshman GPA for students whose ACT test score
is 28. Interpret your confidence interval. Hint: Use R function predict(). (2.5p)

5. Anne obtained a score of 28 on the entrance test. Predict her freshman GPA using a 95%
prediction interval. Interpret your prediction interval. Hint: Use R function predict(). (2.5p)

6. Is the prediction interval in part 5) wider than the confidence interval in part 4)? Explain.
(2.5p)


_PROOF_

1. 

```{r p3}
gpa = read_csv(here::here("data/GPA.csv")) %>%
  janitor::clean_names()

plot_1 =
  gpa %>%
  ggplot(aes(x = act, y = gpa)) +
  geom_point() +
  geom_smooth(method = "lm")

gpa_den =
  gpa %>%
  ggplot(aes(x = gpa)) +
  geom_density() +
  coord_flip() +
  labs(x = "",
       y = "")

act_den =
  gpa %>%
  ggplot(aes(x = act)) +
  geom_density() +
  labs(x = "",
       y = "") +
  labs(title = "GPA vs ACT")

lay = "
AAAA#
BBBBC
BBBBC
BBBBC"

plot_1 =
  act_den + plot_1 + gpa_den +plot_layout(design = lay)
```

```{r p3_reg}
gpa_model =
  lm(gpa ~ act, data = gpa)

gpa_test =
  anova(gpa_model)

show(plot_1)

gpa_test

result = summary(gpa_model)

gpa_ci =
  predict(gpa_model, tibble(act = c(28)), interval = "confidence") %>% as.tibble()
gpa_pi =
  predict(gpa_model, tibble(act = c(28)), interval = "prediction") %>% as.tibble()

gpa_model = broom::tidy(gpa_model)
```

$H_0~:~\beta_1 = 0$(there's no association) 

$H_1~:~\beta_1\ne 0$ 

$error~sum~of~squares(SSE) = \sum_{i=1}^k(y_{i}-\bar{y})^2$

$regression~sum~of~squares(SSR) = \sum_{i=1}^k(\hat{y_{i}}-\bar{y})^2$

$MSR = \frac{\sum_{i=1}^k(\hat{y_{i}}-\bar{y})^2}{k-1}~(k=2)$

$MSE = \frac{\sum_{i=1}^k(y_{i}-\bar{y})^2}{n-k}$

$F_{statistics} = \frac{MSR}{MSE} \sim F(k-1,n-k)$

$Reject ~ H_0 ~ if ~ F>F_{k-1,n-k,1-\alpha}$

$Fail ~ reject ~ H_0 ~ if ~F<F_{k-1,n-k,1-\alpha}$

At 95% confidence level, with F = `r gpa_test %>% broom::tidy() %>% drop_na() %>% pull(statistic)` and critical value of $F_{0.95,1,n-1}$
, we reject the Null hypothesis and conclude that there's linear 
association between GPA and ACT.

2. $$GPA = \hat{\beta_0} + \hat{\beta_1} * ACT$$

$$GPA = `r gpa_model[1,"estimate"] %>% round(3)` + `r gpa_model[2,"estimate"] %>% round(3)`* ACT$$
```{r}
knitr::knit_print(result)
```


3. Confidence Interval for $\beta_1$ is 
$$\begin{aligned}
\hat{\beta_1} \pm t_{n-2, 1-\alpha/2} * se(\hat{\beta_1})\\
= `r gpa_model %>% filter(term == "act") %>% pull(estimate)` \pm `r qt(0.975,nrow(gpa)-2)` *  `r gpa_model %>% filter(term == "act") %>% pull(std.error)`
\end{aligned}$$

$$(`r gpa_model %>% filter(term == "act") %>% pull(estimate) - qt(0.975,nrow(gpa)-2)*gpa_model %>% filter(term == "act") %>% pull(std.error)`,
`r gpa_model %>% filter(term == "act") %>% pull(estimate) + qt(0.975,nrow(gpa)-2)*gpa_model %>% filter(term == "act") %>% pull(std.error)`)$$

So at 95% confidence level ,the mean change in GPA per 1 ACT score is somewhere within this
 interval, and it doesn't contain 0. The AO might take a interest in this association, and include as much as high ACT score candidate for higher average performance in the new enviroment. Or they flag the candidate whom might fall behind and take action to make sure that they catch up. 

4. The 95% CI for $X_h$ = 28 is $(`r gpa_ci %>% select(- fit) %>% pull(lwr)`,`r gpa_ci %>% select(- fit) %>% pull(upr)` )$, with 95% confidence, the true mean of estimator Yh lies between somewhere in this range.

5. The 95% PI for $X_h$ = 28 is $(`r gpa_pi %>% select(- fit) %>% pull(lwr)`,`r gpa_pi %>% select(- fit) %>% pull(upr)` )$, with 95% confidence, the true estimator Yh lies between somewhere within this interval.

6. The PI is wider than the CI because CI is interval of the mean of $\hat{Y} = \beta_0 + \beta_1 * X$, 
while the PI is interval of the actual estimation of $\hat{Y} = \beta_0 + \beta_1 * X +\varepsilon$, the standard error for PI is larger than the CI, so the PI is always larger than the CI.